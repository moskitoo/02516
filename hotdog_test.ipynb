{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "#     def __init__(self, train=True, transform=None, data_path='/content/drive/MyDrive/datasets/hotdog_nothotdog', train_ratio=0.8):\n",
    "#         'Initialization'\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Load all images from both train and test directories\n",
    "#         all_image_paths = glob.glob(os.path.join(data_path, '*/*/*.jpg'))\n",
    "\n",
    "#         # Split the images into classes\n",
    "#         image_classes = {os.path.split(os.path.split(path)[0])[\n",
    "#             1]: [] for path in all_image_paths}\n",
    "#         for path in all_image_paths:\n",
    "#             class_name = os.path.split(os.path.split(path)[0])[1]\n",
    "#             image_classes[class_name].append(path)\n",
    "\n",
    "#         # Shuffle and split the dataset based on the specified ratio\n",
    "#         self.image_paths = []\n",
    "#         for class_name, paths in image_classes.items():\n",
    "#             random.shuffle(paths)  # Shuffle the images for randomness\n",
    "#             split_index = int(len(paths) * train_ratio)\n",
    "#             if train:\n",
    "#                 self.image_paths.extend(paths[:split_index])  # Training data\n",
    "#             else:\n",
    "#                 self.image_paths.extend(paths[split_index:])  # Testing data\n",
    "\n",
    "#         self.name_to_label = {c: id for id,\n",
    "#                               c in enumerate(image_classes.keys())}\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Returns the total number of samples'\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         'Generates one sample of data'\n",
    "#         image_path = self.image_paths[idx]\n",
    "\n",
    "#         image = Image.open(image_path)\n",
    "#         c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "#         y = self.name_to_label[c]\n",
    "#         X = self.transform(image)\n",
    "#         return X, y\n",
    "\n",
    "\n",
    "class Hotdog_NotHotdog(torch.utils.data.Dataset):\n",
    "    def __init__(self, train, transform, data_path='./data/hotdog_nothotdog'):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(\n",
    "            data_path + '/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "        X = self.transform(image)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "def compute_pca_from_dataset(dataset):\n",
    "    # Collect all the images into a list\n",
    "    images = []\n",
    "    for img in dataset:\n",
    "        # Reshape each image to (N, 3) for RGB\n",
    "        images.append(np.array(img).reshape(-1, 3))\n",
    "\n",
    "    pixels = np.vstack(images)  # Stack all images into a single (M, 3) array\n",
    "    cov_matrix = np.cov(pixels, rowvar=False)  # Calculate covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(\n",
    "        cov_matrix)  # Eigen decomposition\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "def apply_pca_color_jitter(image, eigenvalues, eigenvectors):\n",
    "    # Draw random variables from a Gaussian\n",
    "    alpha = np.random.normal(0, 0.1, 3)  # One for each channel\n",
    "    # Apply PCA jitter\n",
    "    jitter = np.dot(eigenvectors, alpha * eigenvalues)\n",
    "    # Convert image to array and add jitter\n",
    "    img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "    img_jittered = img_array + jitter  # Add jitter\n",
    "    img_jittered = np.clip(img_jittered, 0, 1)  # Ensure values stay in [0, 1]\n",
    "    # Convert back to image\n",
    "    return Image.fromarray((img_jittered * 255).astype(np.uint8))\n",
    "\n",
    "\n",
    "def load_and_transform_dataset(image_resize: int = 224, batch_size: int = 64, train_ratio: float = 0.8, recalculate_normalization: bool = False, data_path='/content/drive/MyDrive/datasets/hotdog_nothotdog'):\n",
    "\n",
    "    min_scale = 256\n",
    "    max_scale = 480\n",
    "    target_size = (image_resize, image_resize)\n",
    "\n",
    "    train_dataset_no_transform = Hotdog_NotHotdog(\n",
    "        train=True, return_image_only=True, data_path=data_path)\n",
    "    eigenvalues, eigenvectors = compute_pca_from_dataset(\n",
    "        train_dataset_no_transform)\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.5244, 0.4443, 0.3621],\n",
    "        std=[0.2679, 0.2620, 0.2733],\n",
    "    )\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda img: img.resize(\n",
    "            (random.randint(min_scale, max_scale),\n",
    "             int(img.size[1] * (random.randint(min_scale, max_scale) / img.size[0])))\n",
    "        )),\n",
    "        # transforms.Lambda(lambda img: apply_pca_color_jitter(\n",
    "        #     img, eigenvalues, eigenvectors)),\n",
    "        # transforms.RandomCrop(target_size),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        # Resizing for consistency look into the paper!!!\n",
    "        transforms.Resize((256, 256)),\n",
    "        # transforms.CenterCrop(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        # normalize,\n",
    "    ])\n",
    "\n",
    "    trainset = Hotdog_NotHotdog(\n",
    "        train=True, transform=train_transform, data_path=data_path)\n",
    "    testset = Hotdog_NotHotdog(\n",
    "        train=False, transform=test_transform, data_path=data_path)\n",
    "    train_loader = DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "    test_loader = DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "    return trainset, testset, train_loader, test_loader\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
